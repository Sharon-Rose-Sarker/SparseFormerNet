# SparseFormerNet
A Transformer architecture enhanced with CBAM (Convolutional Block Attention Module) for improved feature representation. It also integrates sparse self-attention mechanisms to optimize performance on long sequences.

![image](https://github.com/user-attachments/assets/1fd7192c-fac2-46f8-bd05-482a8610eab0)
